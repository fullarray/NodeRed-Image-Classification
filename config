[{"id":"ee69c3f9.119623","type":"change","z":"130b735ff.cf48ca","name":"Extract images URL","rules":[{"t":"set","p":"payload","pt":"msg","to":"payload.imageurl","tot":"msg"}],"action":"","property":"","from":"","to":"","reg":false,"x":250,"y":300,"wires":[["8a17bd8a.75e84"]]},{"id":"b47ffc6b.4b8","type":"switch","z":"30b735ff.cf48ca","name":"Check image url","property":"payload.imageurl","propertyType":"msg","rules":[{"t":"null"},{"t":"else"}],"checkall":"true","outputs":2,"x":280,"y":140,"wires":[["12ebc1eb.ed143e"],["ee69c3f9.11964"]]},{"id":"df98266f.2067d8","type":"http in","z":"30b735ff.cf48ca","name":"","url":"/people","method":"get","swaggerDoc":"","x":90,"y":140,"wires":[["b47ffc6b.4b8"]]},{"id":"12ebc1eb.ed143e","type":"template","z":"30b735ff.cf48ca","name":"Prompt images","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"<h1>Welcome to a Watson Visual Recognition sample Face Detection app</h1>\n<H2>Recognize anyone?</H2>\n<form  action=\"{{req._parsedUrl.pathname}}\">\n    <img src=\"http://sysrun.haifa.il.ibm.com/ibm/history/exhibits/chairmen/images/watsonsr.jpg\" height='200'/>\n    <img src=\"http://www.awaken.com/wp-content/uploads/2015/05/forbes.jpg\" height='200'/>\n    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/LinuxCon_Europe_Linus_Torvalds_03.jpg/220px-LinuxCon_Europe_Linus_Torvalds_03.jpg\" height='200'/>\n    <img src=\"http://smashinghub.com/wp-content/uploads/2012/01/nb5.jpg\" height='200'/>\n        <br/>Right-click one of the above images and select Copy image location and paste the URL in the box below.<br>Do an image search for faces, try multiple faces. After you click on an image, to the right it usually says \"View image\" click that to get the URL.<br/>\n    <br>Image URL: <input type=\"text\" name=\"imageurl\"/>\n    <input type=\"submit\" value=\"Analyze\"/>\n</form>","x":540,"y":140,"wires":[["75c9eb5c.8a3614"]]},{"id":"9663cf11.699c3","type":"template","z":"30b735ff.cf48ca","name":"Report faces via HTML template","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"<h1>Visual Recognition v3 Image Analysis</h1>\n    <p>Analyzed image: {{result.images.0.resolved_url}}<br/><img id=\"image\" src=\"{{result.images.0.resolved_url}}\" height=\"200\"/></p>\n    {{^result}}\n        <P>No Face detected</P>\n    {{/result}}\n    <p>Images Processed: {{result.images_processed}}</p>\n    <table border='1'>\n        <thead><tr><th>Age Range</th><th>Confidence</th><th>Gender</th><th>Confidence</th><th>Name</th></tr></thead>\n        {{#result.images.0.faces}}<tr>\n            <td><b>{{age.min}} - {{age.max}}</b></td><td><i>{{age.score}}</i></td>\n            <td>{{gender.gender}}</td><td>{{gender.score}}</td>\n            <td>{{identity.name}} ({{identity.score}})</td>\n        </tr>{{/result.images.0.faces}}\n    </table>\n    <form  action=\"{{req._parsedUrl.pathname}}\">\n        <br><input type=\"submit\" value=\"Try again or go back to the home page\"/>\n    </form>","x":590,"y":240,"wires":[["75c9eb5c.8a3614"]]},{"id":"75c9eb5c.8a3614","type":"http response","z":"30b735ff.cf48ca","name":"","x":890,"y":140,"wires":[]},{"id":"8a17bd8a.75e84","type":"visual-recognition-v3","z":"30b735ff.cf48ca","name":"","apikey":"","image-feature":"detectFaces","x":260,"y":440,"wires":[["9663cf11.699c3","d48ee25e.2b712","deac620e.2153a","d5fd01c8.2a03"]]},{"id":"d48ee25e.2b712","type":"debug","z":"30b735ff.cf48ca","name":"Print msg.result.images","active":true,"console":"false","complete":"result.images","x":570,"y":540,"wires":[]},{"id":"deac620e.2153a","type":"template","z":"30b735ff.cf48ca","name":"Print result via a template","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"// Template functions can access the json array via this .0. notation.\n// See the Watson Visual Recognition v3 API Documentation at\n// https://watson-api-explorer.mybluemix.net/apis/visual-recognition-v3#!/visual-recognition/get_v3_detect_faces\n\nFirst face in result is a {{result.images.0.faces.0.gender.gender}} !","x":570,"y":340,"wires":[["4c4727b8.b3b8d8"]]},{"id":"4c4727b8.b3b8d8","type":"debug","z":"30b735ff.cf48ca","name":"","active":true,"console":"false","complete":"payload","x":910,"y":340,"wires":[]},{"id":"d5fd01c8.2a03","type":"function","z":"30b735ff.cf48ca","name":"Is this a Celebrity","func":"// A function to determine if this image contains a celebrity.\n// Functions can access the msg.result via array indexes\n// Watson Visual Recognition v3 API Documentation is post here:\n// https://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/visual-recognition/api/v3/?node#detect_faces\nvar i=0;\nvar Celebrity=0;\nvar CelebrityName=\"No one famous detected\";\n\n// There might be multiple faces in this image.\n// Loop through the faces and determine if Watson has\n// detected the identity of at least one celebrity.\nwhile ( msg.result.images[0].faces[i] ) {\n    if (msg.result.images[0].faces[i].identity != null) {\n        Celebrity=1;\n        CelebrityName=msg.result.images[0].faces[i].identity.name;\n    }\n    i++;\n}\n\nmsg.payload = CelebrityName;\n// if a Celebrity was found, send the Name to output 1\n// else send the default \"No one famous detected\" to output 2\nif (Celebrity == 1) {\n        return [ msg, null ];\n} else {\n    return [ null, msg ];\n}\n","outputs":"2","noerr":0,"x":550,"y":440,"wires":[["2ab88693.d5477a"],["55215170.aadeb"]]},{"id":"55215170.aadeb","type":"debug","z":"30b735ff.cf48ca","name":"","active":true,"console":"false","complete":"payload","x":910,"y":460,"wires":[]},{"id":"2ab88693.d5477a","type":"template","z":"30b735ff.cf48ca","name":"Paparazzi","field":"payload","fieldType":"msg","format":"handlebars","syntax":"mustache","template":"This image contains a celebrity: {{payload}} !","x":750,"y":400,"wires":[["55215170.aadeb"]]},{"id":"c19211a7.3e6df","type":"comment","z":"30b735ff.cf48ca","name":"Step #1 - Create a Visual Recognition Service","info":"1. Log into your Bluemix account\n2. Navigate to the Bluemix Catalog\n3. Scroll to the Watson Services section\n4. Find and click on the Visual Recognition service\n5. Create an unbounded Visual Recognition instance\n6. Open the new service and navigate to the Service Credentials\n7. Copy the api_key to the clipboard\n8. Open the above \"visual recognition v3\" node and paste your new API Key","x":210,"y":500,"wires":[]}]
